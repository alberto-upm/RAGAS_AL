ragas==0.2.14
langchain-ollama==0.3.0
datasets==3.0.2
unstructured==0.16.1
libmagic==1.0
langchain-huggingface==0.1.2
langchain-nvidia-ai-endpoints==0.3.9
llama-index-llms-huggingface==0.4.2
llama-index-llms-huggingface-api==0.4.1
llama-index==0.12.26

#langchain_huggingface==0.1.0
#huggingface_hub==0.26.1
#transformers==4.46.0
#sentence_transformers==3.2.1
#torch==2.5.0
#text_generation==0.7.0
#google_search_results==2.4.2
#numexpr==2.10.1
#langchainhub==0.1.21
#sentencepiece==0.2.0
#jinja2==3.1.4
#bitsandbytes==0.44.1
#accelerate==1.0.1



# pip install --prefer-binary "unstructured[pdf]"
# PARA LLAMA.py
# pip install langchain
# pip install langchain-ollama

#  pip install --prefer-binary "unstructured[pdf]"
# pip install --prefer-binary "unstructured[md]"
# pip install --upgrade transformers
#  pip install "accelerate>=0.26.0"
#  conda install -c conda-forge libmagic -y


# pip install --upgrade llama-cpp-python
# !CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir
# CMAKE_ARGS="-DGGML_CUDA=on" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir

# pip install langchain

# huggingface-cli download meta-llama/Meta-Llama-3.1-8B --include "original/*" --local-dir Meta-Llama-3.1-8B
# huggingface-cli download meta-llama/Meta-Llama-3.1-70B-Instruct --include "original/*" --local-dir Meta-Llama-3.1-70B-Instruct

# Para langchain-huggingface
# pip install --upgrade --quiet langchain-huggingface text-generation transformers google-search-results numexpr langchainhub sentencepiece jinja2 bitsandbytes accelerate
# Para los embedings 
# sentence_transformers
